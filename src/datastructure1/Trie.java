package datastructure1;

public class Trie {
    public class TireNode{
        public char data;
        public TireNode[] children=new TireNode[26];
        public boolean isEnd;
        public TireNode(){
            this.data=' ';
            this.isEnd=false;
        }
        public TireNode(char data){
            this.data=data;
            this.isEnd=false;
        }
    }
    private TireNode root=new TireNode('/');
    public void insert(String word){
        char[] charArray = word.toCharArray();
        TireNode p=root;
        for(int i=0;i<charArray.length;i++){
            int index=charArray[i]-'a';
            if(p.children[index]==null){
                p.children[index]=new TireNode(charArray[i]);
            }
            p=p.children[index];
        }
        p.isEnd=true;
    }
    public boolean search(String word){
        char[] charArray = word.toCharArray();
        TireNode p=root;
        for(int i=0;i<charArray.length;i++){
            int index=charArray[i]-'a';
            if(p.children[index]==null){
                return false;
            }
            p=p.children[index];
        }
        if(p.isEnd){
            return true;
        }
        return false;
    }
    public boolean startsWith(String prefix){
        char[] charArray = prefix.toCharArray();
        TireNode p=root;
        for(int i=0;i<charArray.length;i++){
            int index=charArray[i]-'a';
            if(p.children[index]==null){
                return false;
            }
            p=p.children[index];
        }
        return true;
    }
}




/*在 Elasticsearch（ES）里，字典树（Trie 树）被用于实现高效的文本查找功能。下面将通俗易懂地讲解其工作原理。
字典树的结构
字典树是一种树形数据结构，其核心思想是 "用空间换时间"。它的每个节点代表一个字符，从根节点到某一节点的路径上经过的字符连接起来，就构成了一个字符串。

举个例子，有三个单词：cat、dog、car，它们在字典树中的结构如下：

plaintext
        根节点
├── c
│   └── a
│       └── t（单词结束）
        │       └── r（单词结束）
        ├── d
    └── o
        └── g（单词结束）

字典树如何加速查找
在 ES 中，字典树主要用于以下两个场景：
        1. 前缀查询（Prefix Query）
当你搜索以 "ca" 开头的单词时，ES 会这样做：

从根节点出发，找到字符 "c"
从 "c" 节点找到字符 "a"
将以 "a" 为根的子树中所有标记为 "单词结束" 的路径找出来
返回结果：cat 和 car

这个过程的时间复杂度是 O(k)，其中 k 是前缀的长度，与索引中的文档数量无关，因此非常高效。
        2. 自动补全（Autocomplete）
当你在搜索框中输入 "ca" 时，ES 会：

同样找到 "ca" 节点
遍历 "ca" 节点的所有子树，收集所有可能的完整单词
返回候选词：cat、car

这个过程也很快，因为只需要遍历部分树结构。
ES 中的具体应用
在 ES 底层，字典树被用于构建 倒排索引（Inverted Index） 的词条字典。每个词条（Term）都会被拆分成字符，存储在字典树中。这样：

当需要查找某个词条时，可以快速定位
        支持高效的前缀搜索和通配符搜索
减少内存占用（相同前缀的词条共享路径）








1. 倒排索引的基本结构
倒排索引是搜索引擎的核心数据结构，它实现了从词条（Term）到文档列表的映射。例如：

词条 "苹果" → 文档 ID [1001, 1005, 2003]
词条 "手机" → 文档 ID [1005, 2001, 3004]

但在海量数据下，有两个关键挑战：

词条字典的高效存储：如何压缩存储数十亿个词条？
词条的快速查找：如何在毫秒级定位到某个词条？
2. 字典树如何存储词条字典
ES 使用字典树（Trie 树）来组织倒排索引中的词条字典。具体做法是：

字符拆分：将每个词条（如 "apple"）拆分为字符序列（a → p → p → l → e）
路径共享：相同前缀的词条共享树的路径

示例：
假设有三个词条：apple、applet、banana，字典树的结构如下：

plaintext
根节点
├── a
│   └── p
│       └── p
│           └── l
│               └── e   → 词条结束，指向文档列表 [1001, 1005]
│                   └── t → 词条结束，指向文档列表 [2003]
├── b
    └── a
        └── n
            └── a
                └── n
                    └── a → 词条结束，指向文档列表 [3004]

特点：

空间效率：相同前缀（如 app）只存储一次
快速查找：通过字符路径直接定位词条
前缀遍历：天然支持前缀查询（如查找以 app 开头的所有词条）
3. 字典树在 ES 中的优化应用
ES 对字典树做了进一步优化：
3.1 FST（Finite State Transducer）
ES 实际使用的是有限状态转移器（FST），它是字典树的压缩变种：

边压缩：将单路径节点合并（如 a → p → p → l 压缩为 appl）
后缀共享：合并相同后缀的词条
内存映射：FST 可直接映射到内存，无需解压

示例：
词条 apple、applet、apply 的 FST 结构：

plaintext
根节点
├── appl → 存储共享前缀
│   ├── e   → 词条结束
│   ├── et  → 词条结束
│   └── y   → 词条结束

3.2 倒排链指针
在字典树的每个词条结束节点，存储：

文档频率（DF）：该词条出现的文档数
倒排链指针：指向磁盘中存储的文档 ID 列表





倒排索引（Inverted Index）的概念与原理
倒排索引是搜索引擎的核心数据结构，它之所以被称为 "倒排"，是因为它与传统的"正向索引" 方向相反。下面通过对比和实例来解释这个概念。
1. 正向索引（Forward Index）
传统的索引方式是 "文档→内容" 的映射，例如：

文档 1："苹果公司发布了新款 iPhone"
文档 2："iPhone 的拍照功能非常出色"
文档 3："华为和苹果都是知名手机品牌"

正向索引结构：

plaintext
文档1 → [苹果, 公司, 发布, 了, 新款, iPhone]
文档2 → [iPhone, 的, 拍照, 功能, 非常, 出色]
文档3 → [华为, 和, 苹果, 都, 是, 知名, 手机, 品牌]

缺点：
当用户搜索关键词（如 "iPhone"）时，需要遍历所有文档的内容，时间复杂度为 O(n)（n 为文档数），在海量数据下效率极低。
2. 倒排索引（Inverted Index）
倒排索引将映射关系反转，变成 "内容→文档" 的结构：

倒排索引结构：

plaintext
苹果 → [文档1, 文档3]
iPhone → [文档1, 文档2]
华为 → [文档3]
发布 → [文档1]
拍照 → [文档2]
...

更详细的结构通常包含：

词条（Term）：经过分词后的单词（如 "苹果"、"iPhone"）
文档频率（DF）：该词条出现的文档数量
倒排列表（Posting List）：包含每个文档的：
文档 ID
词频（Term Frequency）：词条在文档中出现的次数
位置信息（Position）：词条在文档中的位置（用于短语查询）
偏移量（Offset）：词条在原文中的起始和结束位置

示例：

plaintext
iPhone →
  文档频率: 2
  倒排列表: [
    {文档ID: 1, 词频: 1, 位置: [5]},
    {文档ID: 2, 词频: 1, 位置: [1]}
  ]
3. 为什么叫 "倒排"？
正向索引：从文档出发，索引其包含的内容
倒排索引：从内容出发，索引其出现的文档

这种反转的结构使得：

查询效率大幅提升：搜索 "iPhone" 时，直接定位到对应的倒排列表，时间复杂度接近 O(1)
空间占用更小：通过压缩技术（如 FST）优化词条存储
4. 倒排索引的组成部分
倒排索引通常由两部分组成：
4.1 词条字典（Term Dictionary）
存储所有词条的字典，支持快速查找。在 Elasticsearch 中，使用 **FST（有限状态转移器）** 实现：

支持前缀匹配（如查找以 "苹果" 开头的所有词条）
压缩存储，减少内存占用
支持快速定位词条
4.2 倒排列表（Posting List）
存储每个词条对应的文档列表。通常进行以下优化：

压缩存储：使用增量编码（如 Delta 编码）压缩文档 ID
分块存储：将倒排列表分成多个块，块内使用统一的压缩策略
索引缓存：热门词条的倒排列表会被缓存到内存中
5. 倒排索引的优缺点
优点：
查询效率极高：单次查询时间复杂度接近 O (1)
适合全文检索：支持关键词搜索、短语查询、前缀查询等
空间利用率高：通过压缩技术减少存储开销
缺点：
写入性能较差：每次新增文档都需要更新倒排索引，涉及复杂的分词和索引构建过程
不适合实时数据：索引更新存在延迟（ES 默认 1 秒刷新一次）
不适合范围查询：对数值范围查询（如 "价格在 100-200 之间"）支持较弱（需结合 BKD 树等结构）












 分词（Tokenization）的原理
分词是将文本（如 "苹果公司发布了新款 iPhone"）拆分成单个词条（Token）的过程。这个过程通常包含以下步骤：
1.1 字符过滤（Character Filter）
HTML 标签过滤：移除 HTML 标签（如 <p>、<a>）
特殊符号处理：将连字符、斜杠等转换为空格
规范化：将全角字符转为半角，大写转小写

示例：
输入：iPhone XS Max，售价¥12,999！
输出：iphone xs max 售价 12999
1.2 分词器（Tokenizer）
将文本拆分为独立的词条：

单字分词：按单个字符拆分（如中文）
空格分词：按空格拆分（如英文）
词典分词：基于词典匹配（如结巴分词）
N-gram 分词：按 N 个字符为一组拆分

示例：
输入：苹果手机

单字分词：苹、果、手、机
词典分词：苹果、手机
2-gram 分词：苹果、果手、手机
1.3 词条过滤（Token Filter）
停用词过滤：移除无意义的词（如 "的"、"了"、"is"）
词干提取：将词还原为词干（如 "running" → "run"）
同义词处理：将同义词映射到同一个词条（如 "iPhone" → "苹果手机"）

示例：
输入：The quick brown foxes
输出：quick、brown、fox
2. 中文分词的特殊性
中文没有明显的词边界，分词难度更大，常见方法有：

基于词典的分词（如结巴分词）：
匹配词典中的词汇，如 苹果公司 → 苹果、公司
基于机器学习的分词（如 LSTM）：
通过训练模型预测词边界
混合方法：
结合词典和统计方法，提高准确率
3. 海量词条的内存优化
你提到的 "分那么多词，内存要求高" 确实是个问题，但 Elasticsearch 通过多种技术优化内存使用：
3.1 有限状态转移器（FST）
ES 使用 FST 存储词条字典，它有两个关键特性：

前缀共享：相同前缀的词条共享路径（如 apple 和 applet 共享 appl）
后缀压缩：合并相同后缀

示例：
词条 apple、applet、apply 的 FST 结构：

plaintext
根 → a → p → p → l → e → t
                 ↘ y

FST 的优势：

空间效率极高：比哈希表节省 70-90% 的内存
支持快速前缀查询：O (k) 时间复杂度（k 为前缀长度）
内存映射：FST 可直接映射到内存，无需解压
3.2 倒排列表压缩
倒排列表（存储文档 ID）使用增量编码（Delta Encoding）和位图压缩：

Delta 编码：存储文档 ID 的增量（如 [1001, 1005, 2003] → [1001, 4, 998]）
位图压缩：将频繁出现的词条用位图表示，进一步节省空间
3.3 词频统计优化
词频（TF）：每个词条在文档中的出现次数
文档频率（DF）：包含该词条的文档数

ES 通过 DF 对词条进行排序，高频词条优先加载到内存，低频词条存储在磁盘。





在 Elasticsearch（ES）里，分词器对用户输入内容完成拆分后，和字典树（Trie 树）的匹配过程是这样的：
1. 字典树的高效匹配原理
字典树是一种树形结构，其优势在于能够快速完成字符串的前缀匹配。在 ES 里，它主要用于快速定位倒排索引的位置，而非进行全量遍历。当分词器把文本拆分成一个个词元（Token）之后，字典树会按如下方式工作：

按字符遍历：对于每一个词元，字典树会从根节点开始，依据字符的顺序逐个进行匹配。
路径唯一：在树的每一层，字符的路径是唯一确定的，所以在匹配过程中无需回溯。
快速终止：要是某个字符不匹配，就会立即终止当前路径的搜索。
2. ES 中的匹配过程
2.1 前缀匹配加速
ES 会先利用 FST（有限状态转换器）这种数据结构来压缩字典树，进而减少内存的占用，同时加快前缀匹配的速度。对于每个词元，会按以下步骤处理：

python
运行
# 伪代码展示ES中词元与字典树的匹配过程
def match_term_in_trie(term, trie):
    current_node = trie.root
    for char in term:
        # 快速定位到子节点，时间复杂度为O(1)
        if char not in current_node.children:
            return False  # 不匹配，快速终止
        current_node = current_node.children[char]
    # 检查是否为完整词元
    return current_node.is_terminal
2.2 倒排索引定位
一旦在字典树中找到了匹配的词元，ES 会借助字典树节点中记录的指针，直接定位到倒排索引里对应的 postings list（倒排列表），这个过程的时间复杂度是 O (1)。
3. 效率分析
字典树在匹配单个词元时，时间复杂度为 O (k)，这里的 k 指的是词元的长度。由于 k 通常较小，所以实际的匹配效率非常高。ES 的高效性主要体现在以下几个方面：

内存优化：FST 对字典树进行压缩，降低了内存的使用量。
缓存机制：ES 会对热门的查询路径进行缓存，进一步加快匹配速度。
并行搜索：在分布式环境中，搜索操作可以并行执行。
4. 对比全量遍历
传统的全量遍历需要把输入词和字典里的每个词依次进行比较，时间复杂度为 O (n)，这里的 n 是字典的大小。而字典树匹配的时间复杂度仅为 O (k)，和字典的大小没有关系，所以效率要高得多。
总结
ES 中分词结果与字典树的匹配，并非是低效的全量遍历，而是借助前缀匹配快速定位，再结合倒排索引直接访问文档列表，这种组合方式让 ES 能够高效地处理大规模数据的搜索请求。



2.1 前缀匹配加速
ES 会先利用 FST（有限状态转换器）这种数据结构来压缩字典树，进而减少内存的占用，同时加快前缀匹配的速度。对于每个词元，
其实本质上还是从根节点开始对这个词元的字母进行匹配，只不过是一次匹配多个还是一个的区别
你的理解非常准确！FST（有限状态转换器）本质上确实是对字典树的压缩优化，但在匹配逻辑上有一些关键区别。让我详细解释：
1. 匹配逻辑的本质区别
传统字典树匹配
逐字符匹配：从根节点开始，每次处理一个字符，逐级向下查找。
路径遍历：每个字符对应树的一层，必须按顺序遍历路径。
FST 匹配
并行状态转移：利用状态机的特性，可同时评估多个可能的转移路径。
批量字符匹配：通过预计算的转移表，一次处理多个字符（尤其是前缀相同的部分）。
2. FST 的关键优化点
2.1 状态合并与共享
FST 会合并相同后缀的路径，减少冗余节点：

plaintext
传统字典树：
根 -> a -> p -> p -> l -> e (终端)
      \-> p -> l -> e (终端，"apple"和"ape"的前缀被重复存储)

FST优化后：
根 -> a -> p -> p -> l -> e (终端)
             \-> l -> e (终端，共享"ple"路径)
2.2 高效二进制表示
FST 将状态机转换为紧凑的二进制格式，支持内存映射：

无需动态内存分配
利用 CPU 缓存提升访问速度
2.3 前缀预计算
FST 预先计算前缀状态，加速常见前缀的匹配：

python
运行
# 伪代码：FST的前缀匹配优化
def match_with_fst(term, fst):
    # 快速匹配已知前缀
    prefix_state = fst.lookup_prefix(term[:3])  # 假设预计算了前3个字符的状态
    if prefix_state is None:
        return False

    # 从预计算状态开始匹配剩余字符
    return fst.transition(prefix_state, term[3:])
3. 性能对比
操作	传统字典树	FST
内存占用	O (节点数 × 指针大小)	O (状态数 × 转移表)
前缀匹配速度	O (字符数)	O (字符数 / 压缩率)
查询缓存效率	低	高（连续内存访问）
4. ES 中的实际应用
在 ES 中，FST 主要用于：

词项字典（Term Dictionary）：存储所有索引词元
倒排索引导航：快速定位词元对应的倒排列表
前缀查询优化：如prefix查询直接利用 FST 的前缀状态

*/
