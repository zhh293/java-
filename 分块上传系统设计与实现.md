# 分块上传系统设计与实现

## 概述

分块上传是一种将大文件分割成多个小块分别上传的技术，可以有效提升大文件上传的成功率和用户体验。本方案详细介绍了分块上传系统的整体架构、前后端实现细节以及关键流程。

## 系统架构

### 前端职责
- 文件分块处理
- 分块上传调度
- 上传进度展示
- 上传状态管理

### 后端职责
- 上传会话管理
- 分块数据存储
- 文件合并处理
- 上传权限验证

## 核心流程设计

### 1. 初始化上传会话

#### 前端操作
1. 生成唯一上传标识（requestId）
2. 发送初始化请求，携带用户认证信息和文件基本信息

#### 后端实现
```java
// 伪代码示例
@PostMapping("/file/mpupload/init")
public ResponseEntity<InitResponse> initializeUpload(@RequestHeader("Authorization") String auth,
                                                   @RequestBody InitRequest request) {
    // 1. 验证用户身份
    User user = authService.validateToken(auth);
    
    // 2. 验证请求参数
    if (!validateRequest(request)) {
        return ResponseEntity.badRequest().build();
    }
    
    // 3. 生成上传ID
    String uploadId = UUID.randomUUID().toString();
    
    // 4. 创建上传会话记录
    UploadSession session = new UploadSession();
    session.setUploadId(uploadId);
    session.setRequestId(request.getRequestId());
    session.setUserId(user.getId());
    session.setFileName(request.getFileName());
    session.setFileSize(request.getFileSize());
    session.setTotalChunks(request.getTotalChunks());
    session.setStatus(UploadStatus.INITIALIZED);
    session.setCreateTime(LocalDateTime.now());
    
    // 5. 存储到Redis（设置过期时间）
    redisTemplate.opsForHash().put("upload_sessions", uploadId, session);
    redisTemplate.expire("upload_sessions", Duration.ofHours(24)); // 24小时过期
    
    // 6. 返回上传ID
    return ResponseEntity.ok(new InitResponse(uploadId));
}
```

#### Redis存储结构
```
upload_sessions: {
    upload_id: {
        request_id: "unique_request_id",
        user_id: "user_identifier",
        file_name: "original_filename",
        file_size: 10485760,  // 文件总大小
        total_chunks: 10,     // 总块数
        uploaded_chunks: [],  // 已上传的块索引
        status: "INITIALIZED",
        create_time: "2023-01-01T00:00:00Z",
        expire_time: "2023-01-02T00:00:00Z"
    }
}
```

### 2. 分块上传

#### 前端操作
1. 根据uploadId和当前块索引(sliceId)上传对应块
2. 携带必要的认证信息和块信息

#### 后端实现
```java
@PostMapping(value = "/file/mpupload/upload", consumes = MediaType.MULTIPART_FORM_DATA_VALUE)
public ResponseEntity<ChunkUploadResponse> uploadChunk(@RequestParam("upload_id") String uploadId,
                                                      @RequestParam("slice_id") Integer sliceId,
                                                      @RequestParam("request_id") String requestId,
                                                      @RequestParam("data") MultipartFile chunkFile) {
    // 1. 从Redis获取上传会话
    UploadSession session = (UploadSession) redisTemplate.opsForHash().get("upload_sessions", uploadId);
    if (session == null) {
        return ResponseEntity.status(HttpStatus.NOT_FOUND).body(new ErrorResponse("Upload session not found"));
    }
    
    // 2. 验证请求ID和用户身份
    if (!session.getRequestId().equals(requestId)) {
        return ResponseEntity.status(HttpStatus.FORBIDDEN).build();
    }
    
    // 3. 验证分块ID范围
    if (sliceId < 0 || sliceId >= session.getTotalChunks()) {
        return ResponseEntity.badRequest().body(new ErrorResponse("Invalid slice_id"));
    }
    
    // 4. 验证分块是否已存在（幂等性处理）
    Set<Integer> uploadedChunks = session.getUploadedChunks();
    if (uploadedChunks.contains(sliceId)) {
        log.info("Chunk {} already uploaded for upload_id {}", sliceId, uploadId);
        return ResponseEntity.ok(new ChunkUploadResponse("Chunk already uploaded"));
    }
    
    // 5. 保存分块文件到临时存储
    String chunkPath = saveChunkToTempStorage(uploadId, sliceId, chunkFile);
    
    // 6. 更新上传状态
    uploadedChunks.add(sliceId);
    session.setUploadedChunks(uploadedChunks);
    
    // 7. 检查是否所有块都已上传
    if (uploadedChunks.size() == session.getTotalChunks()) {
        session.setStatus(UploadStatus.ALL_UPLOADED);
    } else {
        session.setStatus(UploadStatus.PARTIAL_UPLOADED);
    }
    
    // 8. 更新Redis中的会话信息
    redisTemplate.opsForHash().put("upload_sessions", uploadId, session);
    
    return ResponseEntity.ok(new ChunkUploadResponse("Chunk uploaded successfully"));
}

private String saveChunkToTempStorage(String uploadId, Integer sliceId, MultipartFile chunkFile) {
    // 创建临时存储目录
    String tempDir = "/temp/uploads/" + uploadId + "/";
    Path dirPath = Paths.get(tempDir);
    try {
        Files.createDirectories(dirPath);
    } catch (IOException e) {
        throw new RuntimeException("Failed to create temp directory", e);
    }
    
    // 保存分块文件
    String chunkFileName = "chunk_" + sliceId + "_" + System.currentTimeMillis();
    Path chunkPath = dirPath.resolve(chunkFileName);
    
    try {
        Files.copy(chunkFile.getInputStream(), chunkPath, StandardCopyOption.REPLACE_EXISTING);
        return chunkPath.toString();
    } catch (IOException e) {
        throw new RuntimeException("Failed to save chunk file", e);
    }
}
```

#### 临时存储策略
- 按uploadId创建独立目录
- 每个分块以sliceId命名
- 设置合理的清理策略（定时清理未完成的上传）

### 3. 上传完成处理

#### 前端操作
- 发送完成请求，携带uploadId和requestId

#### 后端实现
```java
@PostMapping("/file/mpupload/complete")
public ResponseEntity<CompleteResponse> completeUpload(@RequestBody CompleteRequest request) {
    String uploadId = request.getUploadId();
    String requestId = request.getRequestId();
    
    // 1. 从Redis获取上传会话
    UploadSession session = (UploadSession) redisTemplate.opsForHash().get("upload_sessions", uploadId);
    if (session == null) {
        return ResponseEntity.status(HttpStatus.NOT_FOUND).body(new ErrorResponse("Upload session not found"));
    }
    
    // 2. 验证请求ID
    if (!session.getRequestId().equals(requestId)) {
        return ResponseEntity.status(HttpStatus.FORBIDDEN).build();
    }
    
    // 3. 验证是否所有块都已上传
    Set<Integer> uploadedChunks = session.getUploadedChunks();
    if (uploadedChunks.size() != session.getTotalChunks()) {
        return ResponseEntity.badRequest().body(new ErrorResponse("Not all chunks uploaded"));
    }
    
    // 4. 合并所有分块
    String mergedFilePath = mergeChunks(session);
    
    // 5. 验证合并后的文件大小
    File mergedFile = new File(mergedFilePath);
    if (mergedFile.length() != session.getFileSize()) {
        return ResponseEntity.badRequest().body(new ErrorResponse("File size mismatch after merge"));
    }
    
    // 6. 执行业务逻辑（如病毒扫描、格式验证等）
    if (!validateMergedFile(mergedFile)) {
        return ResponseEntity.badRequest().body(new ErrorResponse("File validation failed"));
    }
    
    // 7. 将文件移动到永久存储位置
    String permanentPath = moveToFileStorage(mergedFilePath, session);
    
    // 8. 更新会话状态为已完成
    session.setStatus(UploadStatus.COMPLETED);
    session.setPermanentPath(permanentPath);
    redisTemplate.opsForHash().put("upload_sessions", uploadId, session);
    
    // 9. 清理临时文件
    cleanupTempFiles(uploadId);
    
    // 10. 返回最终结果
    return ResponseEntity.ok(new CompleteResponse(permanentPath));
}

private String mergeChunks(UploadSession session) {
    String uploadId = session.getUploadId();
    String tempDir = "/temp/uploads/" + uploadId + "/";
    String outputPath = "/temp/uploads/" + uploadId + "/merged_file.tmp";
    
    try (FileChannel outputChannel = new FileOutputStream(outputPath).getChannel()) {
        for (int i = 0; i < session.getTotalChunks(); i++) {
            // 查找对应块的临时文件
            Path chunkPattern = Paths.get(tempDir).resolve("chunk_" + i + "_*");
            Path chunkPath = findChunkFile(chunkPattern);
            
            try (FileChannel inputChannel = new FileInputStream(chunkPath.toFile()).getChannel()) {
                inputChannel.transferTo(0, inputChannel.size(), outputChannel);
            }
        }
    } catch (IOException e) {
        throw new RuntimeException("Failed to merge chunks", e);
    }
    
    return outputPath;
}

private void cleanupTempFiles(String uploadId) {
    String tempDir = "/temp/uploads/" + uploadId + "/";
    try {
        FileUtils.deleteDirectory(new File(tempDir));
    } catch (IOException e) {
        log.error("Failed to clean up temp files for upload_id: {}", uploadId, e);
    }
}
```

## 安全措施

### 1. 身份验证
- 所有请求都需要有效的认证token
- 验证用户是否有权限上传文件

### 2. 参数验证
- 验证文件大小、类型、分块数量等参数
- 防止恶意构造超大文件或过多分块

### 3. 频率限制
- 限制单个用户的并发上传数量
- 防止恶意占用服务器资源

### 4. 文件安全
- 上传完成后进行病毒扫描
- 验证文件类型和内容是否匹配

## 性能优化

### 1. 并发上传
- 允许同时上传多个分块
- 控制并发数量避免服务器过载

### 2. 断点续传
- 记录已上传的分块信息
- 支持从中断点继续上传

### 3. 缓存策略
- 合理设置Redis过期时间
- 定期清理无效的上传会话

## 错误处理

### 1. 上传失败
- 提供详细的错误信息
- 支持单个分块重传

### 2. 网络中断
- 自动重连机制
- 断点续传功能

### 3. 资源清理
- 定时清理过期的上传会话
- 自动删除临时文件

## 监控与日志

### 1. 操作日志
- 记录所有上传操作
- 包括用户、文件、时间等信息

### 2. 性能监控
- 监控上传成功率
- 统计平均上传时间

### 3. 异常告警
- 监控上传失败率
- 及时发现系统问题

## 总结

分块上传系统通过合理的架构设计和安全措施，可以有效处理大文件上传需求，提升用户体验和系统稳定性。关键在于：
1. 安全的身份验证和权限控制
2. 可靠的状态管理和进度跟踪
3. 高效的文件处理和存储策略
4. 完善的错误处理和资源清理机制